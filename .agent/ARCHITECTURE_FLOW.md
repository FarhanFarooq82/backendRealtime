# Real-Time Translation System - Complete Architecture Flow

**Version:** 2.0  
**Last Updated:** 2026-02-03  
**Purpose:** Complete end-to-end flow documentation for developers

---

## ğŸ“‹ Table of Contents

1. [System Overview](#system-overview)
2. [Complete Conversation Cycle](#complete-conversation-cycle)
   - [Phase 1: Audio Analysis](#phase-1-audio-analysis-parallel-tracks)
   - [Phase 2: Translation (Dual GenAI)](#phase-2-dual-genai-tracks-parallel--independent)
   - [Phase 3: AI Assistant Mode](#phase-3-ai-assistant-mode-intent-detection)
3. [Data Structures](#data-structures)
4. [Session Management](#session-management)
5. [Performance Characteristics](#performance-characteristics)

---

## ğŸ¯ System Overview

### Architecture Principles

- **Dual-Track Processing**: Pulse (fast) and Brain (deep) run in parallel
- **Non-Blocking TTS**: Audio plays while refinement continues
- **Sequential STT**: Google primary, Azure fallback (not parallel)
- **Speaker Consistency**: ONNX + Neural Roster ensure voice continuity
- **AI-Driven Summaries**: Native language generation with RTL support

### Key Technologies

- **STT**: Google Cloud Speech-to-Text V2 (primary), Azure Speech (fallback)
- **Speaker Detection**: ONNX model (local inference)
- **Translation**: Gemini Flash 1.5 (Pulse), Gemini Pro 1.5 (Brain)
- **TTS**: Azure Neural Voices with speaker assignment
- **Communication**: SignalR WebSockets
- **Summary**: Parallel bilingual generation with AI-native headings

---

## ğŸ”„ Complete Conversation Cycle

### Phase 1: Audio Analysis (Parallel Tracks)

```
Frontend Audio (WebM Opus)
        â”‚
        â””â”€â†’ SignalR: Hub.ReceiveAudioAsync()
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ ConversationOrchestrator               â”‚
        â”‚ HandleIncomingAudioAsync()             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”‚ âœ¨ IMMEDIATE FAN-OUT (PARALLEL!)
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                            â”‚
        â”‚                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STT ORCHESTRATOR      â”‚    â”‚ ONNX SPEAKER DETECTION     â”‚
â”‚ (Text Extraction)     â”‚    â”‚ (Local ML Inference)       â”‚
â”‚                       â”‚    â”‚                            â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Google STT V2   â”‚  â”‚    â”‚ â”‚ Audio Features (MFCC)  â”‚ â”‚
â”‚ â”‚ (Primary)       â”‚  â”‚    â”‚ â”‚         â†“              â”‚ â”‚
â”‚ â”‚                 â”‚  â”‚    â”‚ â”‚ Speaker Embedding      â”‚ â”‚
â”‚ â”‚ Per language:   â”‚  â”‚    â”‚ â”‚         â†“              â”‚ â”‚
â”‚ â”‚ - ur-PK: 0.95 âœ“ â”‚  â”‚    â”‚ â”‚ Returns:               â”‚ â”‚
â”‚ â”‚ - da-DK: 0.42   â”‚  â”‚    â”‚ â”‚ - Provisional ID       â”‚ â”‚
â”‚ â”‚ - en-US: 0.23   â”‚  â”‚    â”‚ â”‚   "PROV_SPK_A"         â”‚ â”‚
â”‚ â”‚                 â”‚  â”‚    â”‚ â”‚ - Gender: "Male"       â”‚ â”‚
â”‚ â”‚ Winner: ur-PK   â”‚  â”‚    â”‚ â”‚ - Speaker Confidence   â”‚ â”‚
â”‚ â”‚ Text: "ÛŒÛ..."   â”‚  â”‚    â”‚ â”‚   0.78                 â”‚ â”‚
â”‚ â”‚                 â”‚  â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ If FAIL:        â”‚  â”‚    â”‚                            â”‚
â”‚ â”‚   â†“ Azure STT   â”‚  â”‚    â”‚ â‰ˆ 200ms (very fast)       â”‚
â”‚ â”‚   (Fallback)    â”‚  â”‚    â”‚                            â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                      â”‚                 â†“
â”‚ â‰ˆ 500ms             â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ Results merge at 500ms
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
            Merged Results:
            {
              text: "ÛŒÛ Ù¹ÛŒØ³Ù¹...",
              detectedLanguage: "ur-PK",
              provisionalSpeaker: "PROV_SPK_A",
              speakerConfidence: 0.78,
              gender: "Male"
            }
```

**Key Points:**

- **STT is SEQUENTIAL**: Google first, Azure only on failure
- **ONNX is PARALLEL**: Runs simultaneously with STT
- **Language Detection**: STT tries all configured languages, picks highest confidence
- **Provisional Speaker**: ONNX provides fast speaker ID for TTS

---

### Phase 2: Dual GenAI Tracks (Parallel & Independent)

```
                   â”‚ Merged STT + ONNX Results
                   â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Build Enhanced Translation Request    â”‚
    â”‚ - Text: "ÛŒÛ Ù¹ÛŒØ³Ù¹..."                  â”‚
    â”‚ - Detected language: ur-PK            â”‚
    â”‚ - Target language: da-DK              â”‚
    â”‚ - Recent history (5 turns)            â”‚
    â”‚ - Speaker hint: PROV_SPK_A            â”‚
    â”‚ - ONNX confidence: 0.78               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ âœ¨ FAN-OUT TO PARALLEL GENAI TRACKS
                   â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                â”‚
    â”‚ (BOTH RUN SIMULTANEOUSLY!)     â”‚
    â”‚                                â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PULSE TRACK          â”‚    â”‚ BRAIN TRACK                   â”‚
â”‚ (TTS Priority)       â”‚    â”‚ (Deep Analysis)               â”‚
â”‚                      â”‚    â”‚                               â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Gemini Flash 1.5 â”‚ â”‚    â”‚ â”‚ Gemini Pro 1.5            â”‚ â”‚
â”‚ â”‚ (Fastest Model)  â”‚ â”‚    â”‚ â”‚ (Smart Model)             â”‚ â”‚
â”‚ â”‚                  â”‚ â”‚    â”‚ â”‚                           â”‚ â”‚
â”‚ â”‚ Input:           â”‚ â”‚    â”‚ â”‚ Input:                    â”‚ â”‚
â”‚ â”‚ - Text           â”‚ â”‚    â”‚ â”‚ - Text                    â”‚ â”‚
â”‚ â”‚ - Source: ur-PK  â”‚ â”‚    â”‚ â”‚ - Source: ur-PK           â”‚ â”‚
â”‚ â”‚ - Target: da-DK  â”‚ â”‚    â”‚ â”‚ - Target: da-DK           â”‚ â”‚
â”‚ â”‚ - Min context    â”‚ â”‚    â”‚ â”‚ - Full history            â”‚ â”‚
â”‚ â”‚                  â”‚ â”‚    â”‚ â”‚ - Speaker context         â”‚ â”‚
â”‚ â”‚ Returns:         â”‚ â”‚    â”‚ â”‚ - ONNX speaker hint       â”‚ â”‚
â”‚ â”‚ - Translation:   â”‚ â”‚    â”‚ â”‚ - Significant turns       â”‚ â”‚
â”‚ â”‚   "Dette er..."  â”‚ â”‚    â”‚ â”‚                           â”‚ â”‚
â”‚ â”‚ - Gender hint    â”‚ â”‚    â”‚ â”‚ Returns:                  â”‚ â”‚
â”‚ â”‚                  â”‚ â”‚    â”‚ â”‚ - Translation:            â”‚ â”‚
â”‚ â”‚ â‰ˆ 800ms         â”‚ â”‚    â”‚ â”‚   "Dette er faktisk..."   â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â”‚ - Speaker ID:             â”‚ â”‚
â”‚          â”‚           â”‚    â”‚ â”‚   "ahmed_khan_xyz"        â”‚ â”‚
â”‚          â–¼           â”‚    â”‚ â”‚ - Speaker name:           â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”‚   "Ahmed Khan"            â”‚ â”‚
â”‚ â”‚ Voice Selector   â”‚ â”‚    â”‚ â”‚ - User confidence: 0.94   â”‚ â”‚
â”‚ â”‚                  â”‚ â”‚    â”‚ â”‚ - Gender/Age metadata     â”‚ â”‚
â”‚ â”‚ Logic:           â”‚ â”‚    â”‚ â”‚ - isSignificant: true     â”‚ â”‚
â”‚ â”‚ 1. Roster check  â”‚ â”‚    â”‚ â”‚ - Decision type: CONFIRM  â”‚ â”‚
â”‚ â”‚    PROV_SPK_A?   â”‚ â”‚    â”‚ â”‚                           â”‚ â”‚
â”‚ â”‚    NO â†’ Create   â”‚ â”‚    â”‚ â”‚ â‰ˆ 2-3 seconds            â”‚ â”‚
â”‚ â”‚                  â”‚ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ 2. Assign voice: â”‚ â”‚    â”‚             â”‚                 â”‚
â”‚ â”‚    - Lang: da-DK â”‚ â”‚    â”‚             â–¼                 â”‚
â”‚ â”‚    - Gender: M   â”‚ â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚    â†’ JeppeNeural â”‚ â”‚    â”‚ â”‚ SpeakerRosterService      â”‚ â”‚
â”‚ â”‚                  â”‚ â”‚    â”‚ â”‚ (Neural Roster Mgmt)      â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â”‚                           â”‚ â”‚
â”‚          â”‚           â”‚    â”‚ â”‚ Neural Matching:          â”‚ â”‚
â”‚          â–¼           â”‚    â”‚ â”‚ 1. Known speaker?         â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”‚    "ahmed_khan_xyz"       â”‚ â”‚
â”‚ â”‚ Azure Neural TTS â”‚ â”‚    â”‚ â”‚    â†’ YES: SPK_001         â”‚ â”‚
â”‚ â”‚                  â”‚ â”‚    â”‚ â”‚                           â”‚ â”‚
â”‚ â”‚ Synthesize:      â”‚ â”‚    â”‚ â”‚ 2. Match PROV_SPK_A?      â”‚ â”‚
â”‚ â”‚ - Text: Danish   â”‚ â”‚    â”‚ â”‚    Conf: 0.94 > 0.85      â”‚ â”‚
â”‚ â”‚ - Voice: Jeppe   â”‚ â”‚    â”‚ â”‚    â†’ MERGE & UPGRADE!     â”‚ â”‚
â”‚ â”‚ - Speaker: PROV  â”‚ â”‚    â”‚ â”‚                           â”‚ â”‚
â”‚ â”‚                  â”‚ â”‚    â”‚ â”‚ 3. Update roster:         â”‚ â”‚
â”‚ â”‚ Stream chunks:   â”‚ â”‚    â”‚ â”‚    PROV_SPK_A â†’ SPK_001   â”‚ â”‚
â”‚ â”‚ â†’ Frontend â”€â”€â”€â”€â”€â”€â”¼â”€â”¼â”€â”  â”‚ â”‚    Keep voice: Jeppe      â”‚ â”‚
â”‚ â”‚ â†’ Frontend â”€â”€â”€â”€â”€â”€â”¼â”€â”¼â”€â”¤  â”‚ â”‚                           â”‚ â”‚
â”‚ â”‚ â†’ Frontend â”€â”€â”€â”€â”€â”€â”¼â”€â”¼â”€â”¤  â”‚ â”‚ Result: SPK_001           â”‚ â”‚
â”‚ â”‚ â†’ ...            â”‚ â”‚ â”‚  â”‚ â”‚   "Ahmed Khan"            â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚  â”‚ â”‚   JeppeNeural (same!)     â”‚ â”‚
â”‚                      â”‚ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ âœ… USER HEARS AUDIO  â”‚ â”‚  â”‚             â”‚                 â”‚
â”‚    ~1.5s latency!    â”‚ â”‚  â”‚             â–¼                 â”‚
â”‚                      â”‚ â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ âŒ NO ConversationItemâ”‚ â”‚  â”‚ â”‚ ConversationTurn          â”‚ â”‚
â”‚    to frontend yet!  â”‚ â”‚  â”‚ â”‚                           â”‚ â”‚
â”‚                      â”‚ â”‚  â”‚ â”‚ Create/Update:            â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â”‚ {                         â”‚ â”‚
                         â”‚  â”‚ â”‚   SequenceNumber: N,      â”‚ â”‚
                         â”‚  â”‚ â”‚   SpeakerId: "SPK_001",   â”‚ â”‚
                         â”‚  â”‚ â”‚   SpeakerName: "Ahmed",   â”‚ â”‚
                         â”‚  â”‚ â”‚   Language: "ur-PK",      â”‚ â”‚
                         â”‚  â”‚ â”‚   TargetLang: "da-DK",    â”‚ â”‚
                         â”‚  â”‚ â”‚   OriginalText: "ÛŒÛ...",  â”‚ â”‚
                         â”‚  â”‚ â”‚   TranslatedText: "Dette",â”‚ â”‚
                         â”‚  â”‚ â”‚   TranscriptionConf: 0.78,â”‚ â”‚
                         â”‚  â”‚ â”‚   SpeakerConf: 0.94,      â”‚ â”‚
                         â”‚  â”‚ â”‚   TranslationConf: 0.94,  â”‚ â”‚
                         â”‚  â”‚ â”‚   IsSignificant: true,    â”‚ â”‚
                         â”‚  â”‚ â”‚   Metadata: { ... }       â”‚ â”‚
                         â”‚  â”‚ â”‚ }                         â”‚ â”‚
                         â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                         â”‚  â”‚             â”‚                 â”‚
                         â”‚  â”‚             â–¼                 â”‚
                         â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                         â”‚  â”‚ â”‚ ConversationSession       â”‚ â”‚
                         â”‚  â”‚ â”‚ AddConversationTurn()     â”‚ â”‚
                         â”‚  â”‚ â”‚                           â”‚ â”‚
                         â”‚  â”‚ â”‚ Auto-assign sequence:     â”‚ â”‚
                         â”‚  â”‚ â”‚   turn.SequenceNumber =   â”‚ â”‚
                         â”‚  â”‚ â”‚     history.Count + 1     â”‚ â”‚
                         â”‚  â”‚ â”‚                           â”‚ â”‚
                         â”‚  â”‚ â”‚ Store in repository       â”‚ â”‚
                         â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                         â”‚  â”‚             â”‚                 â”‚
                         â”‚  â”‚             â–¼                 â”‚
                         â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                         â”‚  â”‚ â”‚ Map to Frontend DTO       â”‚ â”‚
                         â”‚  â”‚ â”‚                           â”‚ â”‚
                         â”‚  â”‚ â”‚ FrontendConversationItem: â”‚ â”‚
                         â”‚  â”‚ â”‚ {                         â”‚ â”‚
                         â”‚  â”‚ â”‚   id: "guid",             â”‚ â”‚
                         â”‚  â”‚ â”‚   timestamp: "...",       â”‚ â”‚
                         â”‚  â”‚ â”‚   speakerName: "Ahmed",   â”‚ â”‚
                         â”‚  â”‚ â”‚   speakerConfidence: 0.94,â”‚ â”‚
                         â”‚  â”‚ â”‚   transcriptionText: "ÛŒÛ",â”‚ â”‚
                         â”‚  â”‚ â”‚   sourceLanguageName:     â”‚ â”‚
                         â”‚  â”‚ â”‚     "Urdu",               â”‚ â”‚
                         â”‚  â”‚ â”‚   transcriptionConf: 0.78,â”‚ â”‚
                         â”‚  â”‚ â”‚   translationText: "Dette"â”‚ â”‚
                         â”‚  â”‚ â”‚   targetLanguageName:     â”‚ â”‚
                         â”‚  â”‚ â”‚     "Danish",             â”‚ â”‚
                         â”‚  â”‚ â”‚   translationConf: 0.94,  â”‚ â”‚
                         â”‚  â”‚ â”‚   responseType: "Trans"   â”‚ â”‚
                         â”‚  â”‚ â”‚ }                         â”‚ â”‚
                         â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                         â”‚  â”‚             â”‚                 â”‚
                         â”‚  â”‚             â–¼                 â”‚
                         â”‚  â”‚    SignalR: ReceiveFrontend- â”‚
                         â”‚  â”‚    ConversationItem()         â”‚
                         â”‚  â”‚             â”‚                 â”‚
                         â”‚  â”‚             â–¼                 â”‚
                         â”‚  â”‚       Frontend Updates UI     â”‚
                         â”‚  â”‚                               â”‚
                         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â””â”€â†’ Audio chunks continue streaming...
```

**Key Points:**

- **Pulse Track**: Fast translation â†’ Voice assignment â†’ TTS â†’ Audio streaming
- **Brain Track**: Deep analysis â†’ Speaker ID â†’ Roster update â†’ ConversationItem
- **User Experience**: Hears audio at ~1.5s, sees UI update at ~2.8s
- **No Provisional Item**: Only Brain sends ConversationItem to frontend
- **Voice Continuity**: Provisional speaker upgraded but keeps same voice

---

### Phase 3: AI Assistant Mode (Intent Detection)

When a user asks the AI a question (e.g., "Assistant, what is the capital of Denmark?"), the system switches to AI Assistant mode:

```
User speaks: "Assistant, what is the capital of Denmark?" (in Urdu)
        â”‚
        â–¼
STT + ONNX (same as Phase 1)
        â”‚
        â–¼
Merged Results:
  text: "Ø§Ø³Ø³Ù¹Ù†Ù¹ØŒ ÚˆÙ†Ù…Ø§Ø±Ú© Ú©Ø§ Ø¯Ø§Ø±Ø§Ù„Ø­Ú©ÙˆÙ…Øª Ú©ÛŒØ§ ÛÛ’ØŸ"
  detectedLanguage: "ur-PK"
        â”‚
        â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Build Enhanced Translation Request       â”‚
    â”‚ - Text: "Ø§Ø³Ø³Ù¹Ù†Ù¹ØŒ ÚˆÙ†Ù…Ø§Ø±Ú© Ú©Ø§ Ø¯Ø§Ø±Ø§Ù„Ø­Ú©ÙˆÙ…Øª..." â”‚
    â”‚ - Language: ur-PK                        â”‚
    â”‚ - Target: da-DK                          â”‚
    â”‚ - Context: Recent conversation           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ âœ¨ FAN-OUT TO PARALLEL GENAI
                   â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                               â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PULSE TRACK          â”‚    â”‚ BRAIN TRACK                  â”‚
â”‚                      â”‚    â”‚                              â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Gemini Flash 1.5 â”‚ â”‚    â”‚ â”‚ Gemini Pro 1.5           â”‚ â”‚
â”‚ â”‚                  â”‚ â”‚    â”‚ â”‚                          â”‚ â”‚
â”‚ â”‚ Detects:         â”‚ â”‚    â”‚ â”‚ Detects:                 â”‚ â”‚
â”‚ â”‚ Intent:          â”‚ â”‚    â”‚ â”‚ Intent:                  â”‚ â”‚
â”‚ â”‚ "AI_ASSISTANCE" âœ…â”‚ â”‚    â”‚ â”‚ "AI_ASSISTANCE" âœ…       â”‚ â”‚
â”‚ â”‚                  â”‚ â”‚    â”‚ â”‚                          â”‚ â”‚
â”‚ â”‚ Returns:         â”‚ â”‚    â”‚ â”‚ Generates:               â”‚ â”‚
â”‚ â”‚ {                â”‚ â”‚    â”‚ â”‚ {                        â”‚ â”‚
â”‚ â”‚   intent:        â”‚ â”‚    â”‚ â”‚   intent:                â”‚ â”‚
â”‚ â”‚   "AI_ASSISTANCE"â”‚ â”‚    â”‚ â”‚   "AI_ASSISTANCE",       â”‚ â”‚
â”‚ â”‚ }                â”‚ â”‚    â”‚ â”‚   aiAssistance: {        â”‚ â”‚
â”‚ â”‚                  â”‚ â”‚    â”‚ â”‚     response: (ur-PK)    â”‚ â”‚
â”‚ â”‚ âŒ NO TTS!       â”‚ â”‚    â”‚ â”‚     "ÚˆÙ†Ù…Ø§Ø±Ú© Ú©Ø§ Ø¯Ø§Ø±Ø§Ù„Ø­Ú©ÙˆÙ…Øªâ”‚ â”‚
â”‚ â”‚ (Pulse skips     â”‚ â”‚    â”‚ â”‚      Ú©ÙˆÙ¾Ù† ÛÛŒÚ¯Ù† ÛÛ’Û”"     â”‚ â”‚
â”‚ â”‚  audio for AI!)  â”‚ â”‚    â”‚ â”‚     responseTranslated:  â”‚ â”‚
â”‚ â”‚                  â”‚ â”‚    â”‚ â”‚     (da-DK)              â”‚ â”‚
â”‚ â”‚ But sends:       â”‚ â”‚    â”‚ â”‚     "Hovedstaden i       â”‚ â”‚
â”‚ â”‚ "Thinking..." ğŸ’­ â”‚ â”‚    â”‚ â”‚      Danmark er          â”‚ â”‚
â”‚ â”‚ to frontend      â”‚ â”‚    â”‚ â”‚      KÃ¸benhavn."         â”‚ â”‚
â”‚ â”‚                  â”‚ â”‚    â”‚ â”‚   },                     â”‚ â”‚
â”‚ â”‚ â‰ˆ 800ms         â”‚ â”‚    â”‚ â”‚   speakerId: "ai-asst",  â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â”‚   translation: "" (empty)â”‚ â”‚
â”‚                      â”‚    â”‚ â”‚ }                        â”‚ â”‚
â”‚ âœ… USER SEES:        â”‚    â”‚ â”‚                          â”‚ â”‚
â”‚ "ğŸ¤– Assistant is     â”‚    â”‚ â”‚ â‰ˆ 3-4 seconds           â”‚ â”‚
â”‚  thinking..."        â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                      â”‚    â”‚            â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚            â–¼                 â”‚
                            â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                            â”‚ â”‚ TTS ONLY FROM BRAIN!     â”‚ â”‚
                            â”‚ â”‚ (AI Response â†’ Audio)    â”‚ â”‚
                            â”‚ â”‚                          â”‚ â”‚
                            â”‚ â”‚ Text: AI response in     â”‚ â”‚
                            â”‚ â”‚       ORIGINAL audio langâ”‚ â”‚
                            â”‚ â”‚       (Urdu)             â”‚ â”‚
                            â”‚ â”‚                          â”‚ â”‚
                            â”‚ â”‚ "ÚˆÙ†Ù…Ø§Ø±Ú© Ú©Ø§ Ø¯Ø§Ø±Ø§Ù„Ø­Ú©ÙˆÙ…Øª    â”‚ â”‚
                            â”‚ â”‚  Ú©ÙˆÙ¾Ù† ÛÛŒÚ¯Ù† ÛÛ’Û”"         â”‚ â”‚
                            â”‚ â”‚                          â”‚ â”‚
                            â”‚ â”‚ Language: ur-PK          â”‚ â”‚
                            â”‚ â”‚ Voice: AI Assistant voiceâ”‚ â”‚
                            â”‚ â”‚                          â”‚ â”‚
                            â”‚ â”‚ Stream chunks â†’ Frontend â”‚ â”‚
                            â”‚ â”‚ âœ… USER HEARS ANSWER     â”‚ â”‚
                            â”‚ â”‚    in their language!    â”‚ â”‚
                            â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                            â”‚            â”‚                 â”‚
                            â”‚            â–¼                 â”‚
                            â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                            â”‚ â”‚ Create ConversationItem  â”‚ â”‚
                            â”‚ â”‚                          â”‚ â”‚
                            â”‚ â”‚ TWO items sent:          â”‚ â”‚
                            â”‚ â”‚                          â”‚ â”‚
                            â”‚ â”‚ 1. User Question:        â”‚ â”‚
                            â”‚ â”‚ {                        â”‚ â”‚
                            â”‚ â”‚   speakerName: "Ahmed",  â”‚ â”‚
                            â”‚ â”‚   transcriptionText:     â”‚ â”‚
                            â”‚ â”‚     "Ø§Ø³Ø³Ù¹Ù†Ù¹ØŒ ÚˆÙ†Ù…Ø§Ø±Ú©..."   â”‚ â”‚
                            â”‚ â”‚   sourceLanguageName:    â”‚ â”‚
                            â”‚ â”‚     "Urdu",              â”‚ â”‚
                            â”‚ â”‚   translationText: "",   â”‚ â”‚
                            â”‚ â”‚   targetLanguageName: "", â”‚ â”‚
                            â”‚ â”‚   responseType:          â”‚ â”‚
                            â”‚ â”‚     "Translation"        â”‚ â”‚
                            â”‚ â”‚ }                        â”‚ â”‚
                            â”‚ â”‚                          â”‚ â”‚
                            â”‚ â”‚ 2. AI Answer:            â”‚ â”‚
                            â”‚ â”‚ {                        â”‚ â”‚
                            â”‚ â”‚   speakerName:           â”‚ â”‚
                            â”‚ â”‚     "AI Assistant",      â”‚ â”‚
                            â”‚ â”‚   transcriptionText:     â”‚ â”‚
                            â”‚ â”‚     "ÚˆÙ†Ù…Ø§Ø±Ú© Ú©Ø§ Ø¯Ø§Ø±Ø§Ù„Ø­Ú©ÙˆÙ…Øª â”‚ â”‚
                            â”‚ â”‚      Ú©ÙˆÙ¾Ù† ÛÛŒÚ¯Ù† ÛÛ’Û”",    â”‚ â”‚
                            â”‚ â”‚   sourceLanguageName:    â”‚ â”‚
                            â”‚ â”‚     "Urdu",              â”‚ â”‚
                            â”‚ â”‚   translationText:       â”‚ â”‚
                            â”‚ â”‚     "Hovedstaden i       â”‚ â”‚
                            â”‚ â”‚      Danmark er          â”‚ â”‚
                            â”‚ â”‚      KÃ¸benhavn.",        â”‚ â”‚
                            â”‚ â”‚   targetLanguageName:    â”‚ â”‚
                            â”‚ â”‚     "Danish",            â”‚ â”‚
                            â”‚ â”‚   responseType:          â”‚ â”‚
                            â”‚ â”‚     "AIResponse" âœ¨      â”‚ â”‚
                            â”‚ â”‚ }                        â”‚ â”‚
                            â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                            â”‚            â”‚                 â”‚
                            â”‚            â–¼                 â”‚
                            â”‚   SignalR: Send both items  â”‚
                            â”‚   â†’ Frontend                â”‚
                            â”‚                             â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**AI Assistant Key Points:**

- âœ… **Intent Detection**: Both Pulse and Brain detect "AI_ASSISTANCE" intent
- âŒ **Pulse NO TTS**: When intent is AI_ASSISTANCE, Pulse skips translation TTS
- âœ… **Show "Thinking"**: Frontend shows user that AI is processing
- âœ… **Brain Generates Answer**: Full AI response in original audio language (Urdu)
- âœ… **Brain TTS**: AI answer synthesized to speech in user's language
- âœ… **Two ConversationItems**: 
  - User question (responseType: "Translation")
  - AI answer (responseType: "AIResponse")
- âœ… **Bilingual Answer**: AI response shown in both languages

**Example Dialogue:**

```
User (Urdu): "Ø§Ø³Ø³Ù¹Ù†Ù¹ØŒ ÚˆÙ†Ù…Ø§Ø±Ú© Ú©Ø§ Ø¯Ø§Ø±Ø§Ù„Ø­Ú©ÙˆÙ…Øª Ú©ÛŒØ§ ÛÛ’ØŸ"
             "Assistant, what is the capital of Denmark?"
             
System: [Detects AI_ASSISTANCE intent]
        [Skips translation TTS from Pulse]
        [Shows "ğŸ¤– Assistant is thinking..."]
        
AI (Urdu): "ÚˆÙ†Ù…Ø§Ø±Ú© Ú©Ø§ Ø¯Ø§Ø±Ø§Ù„Ø­Ú©ÙˆÙ…Øª Ú©ÙˆÙ¾Ù† ÛÛŒÚ¯Ù† ÛÛ’Û”"
           "The capital of Denmark is Copenhagen."

Frontend displays:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ‘¤ Ahmed Khan                          â”‚
â”‚ ğŸ‡µğŸ‡° Urdu                               â”‚
â”‚ "Ø§Ø³Ø³Ù¹Ù†Ù¹ØŒ ÚˆÙ†Ù…Ø§Ø±Ú© Ú©Ø§ Ø¯Ø§Ø±Ø§Ù„Ø­Ú©ÙˆÙ…Øª Ú©ÛŒØ§ ÛÛ’ØŸ" â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ¤– AI Assistant                        â”‚
â”‚ ğŸ‡µğŸ‡° Urdu                               â”‚
â”‚ "ÚˆÙ†Ù…Ø§Ø±Ú© Ú©Ø§ Ø¯Ø§Ø±Ø§Ù„Ø­Ú©ÙˆÙ…Øª Ú©ÙˆÙ¾Ù† ÛÛŒÚ¯Ù† ÛÛ’Û”"  â”‚
â”‚ ğŸ‡©ğŸ‡° Danish                             â”‚
â”‚ "Hovedstaden i Danmark er KÃ¸benhavn."  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Intent-Based Flow Decision

```
Gemini determines Intent:
        â”‚
        â”œâ”€â†’ "SIMPLE_TRANSLATION"
        â”‚   â”œâ”€â†’ Pulse: Generate translation â†’ TTS
        â”‚   â””â”€â†’ Brain: Refine translation â†’ ConversationItem
        â”‚
        â””â”€â†’ "AI_ASSISTANCE"
            â”œâ”€â†’ Pulse: Detect intent â†’ Show "Thinking..." â†’ NO TTS
            â””â”€â†’ Brain: Generate AI answer â†’ TTS (audio language) â†’ TWO ConversationItems
```

**Implementation Files:**

- **Intent Detection**: `TranslationPromptService.cs` (Pulse & Brain prompts)
- **Pulse TTS Skip**: `ConversationResponseService.SendPulseAudioOnlyAsync()` 
  ```csharp
  if (pulseResponse.Intent == "SIMPLE_TRANSLATION" && !string.IsNullOrEmpty(pulseResponse.Translation))
  {
      await SendToTTSContinuousAsync(...); // Only for translations!
  }
  ```
- **Brain TTS**: `ConversationResponseService.ProcessAndNotifyAsync()`
  ```csharp
  bool shouldStreamTTS = !translationResponse.IsPulse && translationResponse.Intent == "AI_ASSISTANCE";
  if (shouldStreamTTS) {
      string tts Text = translationResponse.AIAssistance.Response; // Original language!
      string ttsLanguage = translationResponse.AudioLanguage;
  }
  ```
- **AI Item Creation**: `FrontendConversationItemService.CreateFromAIResponse()`



### Timing Diagram

```
Time: 0ms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ 3000ms

Audio Arrives
    â”‚
    â”œâ”€â†’ STT (500ms) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”œâ”€â†’ ONNX (200ms) â”€â”€â”€â”€â”€â”€â”      â”‚
    â”‚                      â–¼      â–¼
    â”‚                  Merge (500ms)
    â”‚                      â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    â”‚                                    â”‚
    â”‚ â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ â”‚ PULSE TRACK   â”‚            â”‚ BRAIN TRACK        â”‚
    â”‚ â”‚               â”‚            â”‚                    â”‚
    â”‚ â”‚ Flash (800ms) â”‚            â”‚ Pro (2000ms)       â”‚
    â”‚ â”‚      â†“        â”‚            â”‚      â†“             â”‚
    â”‚ â”‚ Voice (100ms) â”‚            â”‚ Speaker ID (300ms) â”‚
    â”‚ â”‚      â†“        â”‚            â”‚      â†“             â”‚
    â”‚ â”‚ TTS (600ms)   â”‚            â”‚ Create Turn        â”‚
    â”‚ â”‚      â†“        â”‚            â”‚      â†“             â”‚
    â”‚ â”‚ Audio chunks  â”‚            â”‚ Send Item          â”‚
    â”‚ â”‚ â†’ Frontend    â”‚            â”‚ â†’ Frontend         â”‚
    â”‚ â”‚               â”‚            â”‚                    â”‚
    â”‚ â”‚ âœ… 1500ms     â”‚            â”‚ âœ… 2800ms          â”‚
    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”‚ USER EXPERIENCE:
    â”‚   ~1.5s: Audio starts playing (Pulse complete)
    â”‚   ~2.8s: UI updates with refined data (Brain complete)
```

---

## ğŸ“Š Data Structures

### Backend: ConversationTurn (Internal Storage)

```csharp
public class ConversationTurn
{
    // Ordering & Identification
    public int SequenceNumber { get; set; }        // Auto-assigned: count + 1
    public string TurnId { get; set; }
    public DateTime Timestamp { get; set; }
    
    // Speaker Information
    public string SpeakerId { get; set; }          // "SPK_001"
    public string SpeakerName { get; set; }        // "Ahmed Khan"
    public float SpeakerConfidence { get; set; }   // 0.94 (from Brain)
    
    // Transcription
    public string Language { get; set; }           // "ur-PK" (BCP-47)
    public string OriginalText { get; set; }       // "ÛŒÛ Ø§ÛŒÚ© Ù¹ÛŒØ³Ù¹ ÛÛ’"
    public float TranscriptionConfidence { get; set; } // 0.78 (from ONNX)
    
    // Translation
    public string? TranslatedText { get; set; }    // "Dette er faktisk..."
    public float TranslationConfidence { get; set; } // 0.94 (from Brain)
    
    // Backend-Only Flags
    public bool IsSignificant { get; set; }        // For context building only!
    
    // Metadata (not sent to frontend)
    public Dictionary<string, object> Metadata { get; set; }
}
```

**Usage of `IsSignificant`:**

1. **Storage**: Mark important turns in conversation history
2. **Brain Prompts**: Include recent significant points for better context
3. **Summary**: Highlight key decisions in bilingual summaries
4. **NOT sent to frontend**: Backend-only contextualization

---

### Frontend: FrontendConversationItem (Display DTO)

```csharp
public class FrontendConversationItem
{
    // Turn Identification
    public string Id { get; set; }
    public DateTime Timestamp { get; set; }
    
    // Speaker
    public string SpeakerName { get; set; }        // "Ahmed Khan"
    public float SpeakerConfidence { get; set; }   // 0.94 (from Brain)
    
    // Transcription
    public string TranscriptionText { get; set; }  // "ÛŒÛ Ø§ÛŒÚ© Ù¹ÛŒØ³Ù¹ ÛÛ’"
    public string SourceLanguageName { get; set; } // "Urdu" (NOT "ur-PK")
    public float TranscriptionConfidence { get; set; } // 0.78 (from ONNX)
    
    // Translation
    public string TranslationText { get; set; }    // "Dette er faktisk..."
    public string TargetLanguageName { get; set; } // "Danish" (NOT "da-DK")
    public float TranslationConfidence { get; set; } // 0.94 (from Brain)
    
    // Response Type
    public string ResponseType { get; set; }       // "Translation" | "AIResponse"
}
```

**What's Excluded from Frontend:**

- âŒ `metadata` - Backend analytics only
- âŒ `assignedVoice` - Backend TTS routing only
- âŒ `isSignificant` - Backend context only
- âŒ Language codes - Replaced with readable names

---

### Confidence Sources

| Field | Source | Purpose |
|-------|--------|---------|
| **transcriptionConfidence** | ONNX Speaker Detection (0.78) | Audio analysis accuracy |
| **speakerConfidence** | Brain User Detection (0.94) | Speaker identification accuracy |
| **translationConfidence** | Brain Translation (0.94) | Translation quality score |

---

## ğŸ¯ Session Management

### Session Lifecycle

```
1. Session Creation
   Frontend connects â†’ SignalR Hub
   â†“
   ConversationOrchestrator creates ConversationState
   â†“
   Session stored in repository

2. Active Conversation (N turns)
   Each turn:
   - Audio â†’ STT + ONNX (parallel)
   - Pulse + Brain (parallel)
   - TTS streaming (from Pulse)
   - ConversationItem (from Brain)
   - Turn stored with auto-incrementing SequenceNumber

3. Summary Generation (On-Demand)
   User clicks "Generate Summary"
   â†“
   hub.invoke("RequestSummary")
   â†“
   ConversationLifecycleManager.RequestSummaryAsync()
   â†“
   Parallel bilingual summary generation
   â†“
   SessionSummaryDTO sent to frontend

4. Session Finalization
   User clicks "End Session & Email"
   â†“
   hub.invoke("FinalizeAndMail", [emails])
   â†“
   Generate PDF (mock)
   â†“
   Send emails
   â†“
   SendFinalizationSuccessAsync()
   â†“
   Frontend disconnects SignalR
   â†“
   Session cleaned from repository
```

---

### Summary Generation (Parallel Bilingual)

```
User clicks "Generate Summary"
        â”‚
        â””â”€â†’ hub.invoke("RequestSummary")
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ ConversationLifecycleManager             â”‚
        â”‚ RequestSummaryAsync()                    â”‚
        â”‚                                          â”‚
        â”‚ 1. Fetch all turns (ordered by Sequence) â”‚
        â”‚ 2. Build single-language contexts        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”‚ âœ¨ 50% Token Reduction!
                    â”‚    (Single language per context)
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                          â”‚
        â”‚ (PARALLEL GENERATION!)   â”‚
        â”‚                          â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Primary Context â”‚    â”‚ Secondary Contextâ”‚
    â”‚ (Urdu)          â”‚    â”‚ (Danish)         â”‚
    â”‚                 â”‚    â”‚                  â”‚
    â”‚ For each turn:  â”‚    â”‚ For each turn:   â”‚
    â”‚   If lang=ur-PK â”‚    â”‚   If lang=da-DK  â”‚
    â”‚     Use Originalâ”‚    â”‚     Use Original â”‚
    â”‚   Else          â”‚    â”‚   Else           â”‚
    â”‚     Use Trans   â”‚    â”‚     Use Trans    â”‚
    â”‚                 â”‚    â”‚                  â”‚
    â”‚ Result:         â”‚    â”‚ Result:          â”‚
    â”‚ "Ù…Ø±Ø­Ø¨Ø§..."      â”‚    â”‚ "Hej..."         â”‚
    â”‚ "ÛŒÛ Ù¹ÛŒØ³Ù¹..."    â”‚    â”‚ "Dette er..."    â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                        â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Gemini Flash 1.5   â”‚  â”‚ Gemini Flash 1.5   â”‚
    â”‚                    â”‚  â”‚                    â”‚
    â”‚ GenerateSummary    â”‚  â”‚ GenerateSummary    â”‚
    â”‚ InLanguageAsync    â”‚  â”‚ InLanguageAsync    â”‚
    â”‚ ("ur-PK")          â”‚  â”‚ ("da-DK")          â”‚
    â”‚                    â”‚  â”‚                    â”‚
    â”‚ AI Prompt:         â”‚  â”‚ AI Prompt:         â”‚
    â”‚ "Generate summary  â”‚  â”‚ "Generate summary  â”‚
    â”‚  entirely in Ø§Ø±Ø¯Ùˆ  â”‚  â”‚  entirely in Dansk â”‚
    â”‚  with NATIVE       â”‚  â”‚  with NATIVE       â”‚
    â”‚  culturally-       â”‚  â”‚  culturally-       â”‚
    â”‚  appropriate       â”‚  â”‚  appropriate       â”‚
    â”‚  headings!"        â”‚  â”‚  headings!"        â”‚
    â”‚                    â”‚  â”‚                    â”‚
    â”‚ AI Generates:      â”‚  â”‚ AI Generates:      â”‚
    â”‚ **ØªØ§Ø±ÛŒØ®**: ...    â”‚  â”‚ **Dato**: ...      â”‚
    â”‚ **Ù…Ù‚ØµØ¯**: ...     â”‚  â”‚ **FormÃ¥l**: ...    â”‚
    â”‚ **Ø´Ø±Ú©Ø§Ø¡**: ...    â”‚  â”‚ **Deltagere**: ... â”‚
    â”‚                    â”‚  â”‚                    â”‚
    â”‚ â‰ˆ 5 seconds       â”‚  â”‚ â‰ˆ 5 seconds       â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                        â”‚
          â”‚  Both complete ~5s     â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ SessionSummaryDTO                        â”‚
        â”‚ {                                        â”‚
        â”‚   primary: {                             â”‚
        â”‚     language: "ur-PK",                   â”‚
        â”‚     languageName: "Ø§Ø±Ø¯Ùˆ",                â”‚
        â”‚     isRTL: true,                         â”‚
        â”‚     content: "**ØªØ§Ø±ÛŒØ®**: ..."            â”‚
        â”‚   },                                     â”‚
        â”‚   secondary: {                           â”‚
        â”‚     language: "da-DK",                   â”‚
        â”‚     languageName: "Dansk",               â”‚
        â”‚     isRTL: false,                        â”‚
        â”‚     content: "**Dato**: ..."             â”‚
        â”‚   },                                     â”‚
        â”‚   generatedAt: "2026-02-03T13:00:00Z",   â”‚
        â”‚   totalTurns: 720,                       â”‚
        â”‚   meetingDuration: "04:00:00"            â”‚
        â”‚ }                                        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ SignalR: ReceiveStructuredSummary()
                     â–¼
                  Frontend
```

**Summary Features:**

- âœ… **AI-Native Headings**: No hardcoded dictionaries, AI generates culturally appropriate section names
- âœ… **Parallel Generation**: Primary and secondary summaries generated simultaneously
- âœ… **RTL Support**: `isRTL` flag for proper text direction rendering
- âœ… **Token Efficient**: Single-language contexts reduce token usage by 50%
- âœ… **Universal Language Support**: Works with any language pair

---

## âš¡ Performance Characteristics

### Latency Breakdown

| Operation | Time | Blocking? | Notes |
|-----------|------|-----------|-------|
| **STT (Google)** | 500ms | Yes | Per-language trials, winner selection |
| **STT (Azure)** | 600ms | Yes | Only on Google failure |
| **ONNX Speaker** | 200ms | No | Parallel with STT |
| **Merge Results** | <10ms | Yes | Combine STT + ONNX |
| **Pulse Translation** | 800ms | No | Parallel with Brain |
| **Brain Translation** | 2-3s | No | Deep analysis |
| **Voice Selection** | 100ms | No | Roster lookup |
| **TTS Synthesis** | 600ms | No | Streaming chunks |
| **Audio to Frontend** | ~1.5s | No | User hears voice |
| **UI Update** | ~2.8s | No | ConversationItem displayed |
| **Summary (single)** | 5s | Yes | Per language |
| **Summary (both)** | 5s | Yes | Parallel generation |

### Parallel Operations

```
ğŸ”€ PARALLEL TRACK 1: STT + ONNX
   Duration: max(500ms, 200ms) = 500ms

ğŸ”€ PARALLEL TRACK 2: Pulse + Brain
   Duration: Both run simultaneously
   User Impact: min(1.5s Pulse, 2.8s Brain) = 1.5s to hear audio

ğŸ”€ PARALLEL TRACK 3: Summary Generation
   Duration: max(5s primary, 5s secondary) = 5s total
```

### Token Optimization

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| **Summary Input Tokens** | 115k | 58k | **50% reduction** |
| **Method** | Bilingual context | Single-language contexts | Per-language filtering |
| **API Calls** | 1 combined | 2 parallel | Same latency |

---

## ğŸ¨ Frontend Integration Guide

### SignalR Event Handlers

```typescript
// Audio streaming (from Pulse)
connection.on("ReceiveFrontendTTSChunk", (chunk: FrontendTTSChunk) => {
  // Play audio immediately
  audioPlayer.enqueue(chunk.audioData);
});

// Conversation updates (from Brain)
connection.on("ReceiveFrontendConversationItem", (item: FrontendConversationItem) => {
  // Update UI with refined speaker and translation
  conversationStore.addOrUpdate(item);
});

// Summary (on-demand)
connection.on("ReceiveStructuredSummary", (summary: SessionSummaryDTO) => {
  // Display bilingual summary with RTL support
  summaryView.render(summary);
});

// Session end
connection.on("ReceiveFinalizationSuccess", () => {
  // Show success, disconnect
  showNotification("Email sent!");
  connection.stop();
});
```

### TypeScript Interfaces

```typescript
interface FrontendConversationItem {
  id: string;
  timestamp: string;
  speakerName: string;
  speakerConfidence: number;
  transcriptionText: string;
  sourceLanguageName: string;
  transcriptionConfidence: number;
  translationText: string;
  targetLanguageName: string;
  translationConfidence: number;
  responseType: "Translation" | "AIResponse" | "System";
}

interface SessionSummaryDTO {
  primary: SummarySection;
  secondary: SummarySection;
  generatedAt: string;
  totalTurns: number;
  meetingDuration: string;
}

interface SummarySection {
  language: string;        // BCP-47: "ur-PK"
  languageName: string;    // Native: "Ø§Ø±Ø¯Ùˆ"
  isRTL: boolean;          // For RTL rendering
  content: string;         // Markdown summary
}
```

---

## ğŸ”§ Developer Notes

### Key Architecture Decisions

1. **STT is Sequential, Not Parallel**
   - Google Cloud STT V2 is primary (supports WebM natively)
   - Azure STT is fallback only (requires PCM conversion)
   - Reason: Avoid duplicate processing costs

2. **ConversationItem Only from Brain**
   - Pulse track focuses on fast TTS
   - Brain track handles complete data enrichment
   - Frontend receives single, complete update

3. **Provisional Speaker Strategy**
   - ONNX provides fast speaker ID for TTS voice assignment
   - Brain later confirms/upgrades speaker with neural matching
   - Voice assignment remains consistent through upgrade

4. **isSignificant is Backend-Only**
   - Used for Brain prompt contextualization
   - Helps highlight important turns in summaries
   - NOT exposed to frontend to avoid UI complexity

5. **Language Names vs Codes**
   - Frontend receives human-readable names ("Urdu", not "ur-PK")
   - Backend uses BCP-47 codes for API calls
   - Conversion happens in DTO mapping layer

### Testing Considerations

- **STT Fallback**: Test Google failure scenarios
- **Speaker Merging**: Test provisional â†’ confirmed upgrades
- **RTL Rendering**: Test with Arabic, Urdu, Hebrew summaries
- **Long Sessions**: Test 4-hour meetings (720+ turns)
- **Parallel Timing**: Verify Pulse completes before Brain
- **Voice Consistency**: Verify same speaker keeps same voice across turns

---

## ğŸ“š Related Documentation

- **Model Configuration**: See `LanguageConfigurationService.cs` for RTL language detection
- **Prompt Engineering**: See `TranslationPromptService.cs` for Brain/Pulse prompt templates
- **Speaker Management**: See `SpeakerRosterService.cs` for neural matching algorithm
- **Voice Assignment**: See `AzureSpeakerVoiceAssignmentService.cs` for voice pool logic

---

**Last Updated:** 2026-02-03  
**Maintained By:** Development Team  
**Questions?** Review code comments or consult the team lead.
